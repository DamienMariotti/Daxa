#version 450
#extension GL_KHR_vulkan_glsl : enable
#extension GL_KHR_shader_subgroup : enable
#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_shader_subgroup_basic : enable
#extension GL_EXT_debug_printf : enable

layout(local_size_x = 16, local_size_y = 16, local_size_z = 4) in;

#include <chunkgen/common.glsl>

uint get_uint_bit_index(uvec3 pos) {
    /*
        ->  every two rows are in one uint,
            so the mod 2 or pos.y denoted wich half they are in the uint
    */
    return pos.x + 16 * (pos.y % 2);
}

uint get_uint_array_index(uvec3 pos) {
    /*
        ->  every second y is still on the same uint, skip them
        ->  the size of one xy layer is 16x16 bits wich is 8 uints
    */
    return pos.y / 2 + pos.z * 8;
}

shared uint local_result_copy[32];

void main() {
    uvec3 global_i = gl_GlobalInvocationID.xyz;
    uvec3 world_i = uvec3(p.pos) + global_i * 4;
    uvec3 chunk_i = uvec3(p.pos) / CHUNK_SIZE;
    bool at_least_one_occluding = false;
    for (int x = 0; x < 4; x++) {
        for (int y = 0; y < 4; y++) {
            for (int z = 0; z < 4; z++) {
                vec3 world_pos_sub = world_i;
                world_pos_sub.x += x;
                world_pos_sub.y += y;
                world_pos_sub.z += z;
                uint block_id = load_block_id(world_pos_sub);
                at_least_one_occluding = at_least_one_occluding || is_block_occluding(block_id);
            }
        }
    }
    uint result = 0x00000000;
    if (at_least_one_occluding) {
        result = 0x00000001;
    }
    result = result << get_uint_bit_index(global_i);
    subgroupBarrier();
    uint leader_thread_result = subgroupOr(result);
    subgroupBarrier();
    if (subgroupElect()) {
        uint block_array_index = get_uint_array_index(global_i);
        chunk_block_presence(chunk_i).x4[block_array_index] = leader_thread_result;
        local_result_copy[global_i.z * 8 + global_i.y / 2] = leader_thread_result;
    }

    barrier();
    // end all warps in the workgroup after they completed their work
    // keep two warps alive to write the x16 occlusion data
    // keep two warps, so 64 = 4*4*4 threads alive
    if (gl_SubgroupID > 1)
        return;

    uvec3 x16_out_index = uvec3(
        gl_SubgroupInvocationID & 0x00000003,
        (gl_SubgroupInvocationID >> 2) & 0x00000003,
        /*
            there are 32 sub invocations, so we need to use the
            subgroup id to get the biggest difference or the "sixth" bit
        */
        (gl_SubgroupInvocationID >> 4) & 0x00000003 + gl_SubgroupID << 1);

    at_least_one_occluding = false;
    for (int x = 0; x < 4; x++) {
        for (int y = 0; y < 4; y++) {
            for (int z = 0; z < 4; z++) {
                uint x4_local_array_index = (x16_out_index.z * 4 + z) * 8 + (x16_out_index.y * 4 + y) / 2;
                uint x4_local_uint_mask = 1 << ((x16_out_index.x * 4 + x) + (x16_out_index.y * 4 + y) % 2);
                bool is_x16_occluded = (local_result_copy[x4_local_array_index] & x4_local_uint_mask) != 0;
                at_least_one_occluding = at_least_one_occluding || is_x16_occluded;
            }
        }
    }
    result = 0x00000000;
    if (at_least_one_occluding) {
        result = 0x00000001;
    }

    subgroupBarrier();
    leader_thread_result = subgroupOr(result);
    subgroupBarrier();

    if (subgroupElect()) {
        chunk_block_presence(chunk_i).x16[gl_SubgroupID] = leader_thread_result;
    }
}
