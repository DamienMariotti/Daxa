#version 450
#extension GL_KHR_vulkan_glsl : enable
#extension GL_KHR_shader_subgroup : enable
#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_shader_subgroup_basic : enable
#extension GL_EXT_debug_printf : enable

layout(local_size_x = 1024, local_size_y = 1, local_size_z = 1) in;

#include <chunkgen/common.glsl>

shared uint local_copy[128];
shared uint local_copy_x16[2];

void main() {
    uvec3 chunk_i = uvec3(p.pos) / CHUNK_SIZE;

    for (int n = 0; n < 4; n++) {
        uint virtual_invocation = gl_GlobalInvocationID.x + n * 1024;
        uvec3 x4_i = linear_index_to_x4_packed_index(virtual_invocation);
        uvec3 world_i = uvec3(p.pos) + x4_i * 4;
        bool at_least_one_occluding = false;
        for (int x = 0; x < 4; x++) {
            for (int y = 0; y < 4; y++) {
                for (int z = 0; z < 4; z++) {
                    vec3 world_pos_sub = world_i + uvec3(x,y,z);
                    uint block_id = load_block_id(world_pos_sub);
                    at_least_one_occluding = at_least_one_occluding || is_block_occluding(block_id);
                }
            }
        }
        uint result = 0x00000000;
        if (at_least_one_occluding) {
            result = x4_uint_bit_mask(x4_i);
        }
        subgroupBarrier();
        uint subgroup32_result_packed = subgroupOr(result);
        subgroupBarrier();
        if (subgroupElect()) {
            uint block_array_index = x4_uint_array_index(x4_i);
            chunk_block_presence(chunk_i).x4[block_array_index] = subgroup32_result_packed;
            local_copy[block_array_index] = subgroup32_result_packed;
        }
    }

    memoryBarrierShared();
    // end all warps in the workgroup after they completed their work
    // keep two warps alive to write the x16 occlusion data
    // keep two warps, so 64 = 4*4*4 threads alive
    if (gl_SubgroupID > 1) {
        return;
    }

    uvec3 x16_i = uvec3(
        gl_GlobalInvocationID.x & 0x3,
        (gl_GlobalInvocationID.x >> 2) & 0x3,
        (gl_GlobalInvocationID.x >> 4) & 0x3);

    uvec3 x16_i_4 = uvec3(
        x16_i.x * 4,
        x16_i.y * 4,
        x16_i.z * 4
    );

#ifdef X4_444_PACKING

    uint x4_array_index0 = x4_uint_array_index(x16_i_4);

    bool at_least_one_occluding = (local_copy[x4_array_index0] |
                              local_copy[x4_array_index0 + 1]) != 0;
#else
    bool at_least_one_occluding = false;
    for (int x = 0; x < 4; x++) {
        for (int y = 0; y < 4; y++) {
            for (int z = 0; z < 4; z++) {
                uvec3 x4_i = x16_i_4 + uvec3(x, y, z);
                uint index = x4_uint_array_index(x4_i);
                uint mask = x4_uint_bit_mask(x4_i);
                at_least_one_occluding =
                    at_least_one_occluding || (local_copy[index] & mask) != 0;
            }
        }
    }
#endif
    uint result = 0;
    if (at_least_one_occluding) {
        result = x16_uint_bit_mask(x16_i);
    }
    subgroupBarrier();
    uint subgroup32_result_packed = subgroupOr(result);
    subgroupBarrier();
    if (subgroupElect()) {
        uint uint_index_x16 = x16_uint_array_index(x16_i);
        chunk_block_presence(chunk_i).x16[uint_index_x16] = subgroup32_result_packed;
        local_copy_x16[uint_index_x16] = subgroup32_result_packed;
    }

    // x32:
    memoryBarrierShared();
    // end all warps/threads except one that does the x32
    if (gl_GlobalInvocationID.x >= 8) {
        return;
    }

    uvec3 x32_i = uvec3(
        gl_GlobalInvocationID.x & 0x1,
        (gl_GlobalInvocationID.x >> 1) & 0x1,
        (gl_GlobalInvocationID.x >> 2) & 0x1
    );

    uvec3 x32_i_2 = uvec3(
        x16_i.x * 2,
        x16_i.y * 2,
        x16_i.z * 2
    );
    uint x32_index = x32_uint_array_index(x32_i);

    at_least_one_occluding = false;
    for (int x = 0; x < 2; x++) {
        for (int y = 0; y < 2; y++) {
            for (int z = 0; z < 2; z++) {
                uvec3 x16_i = x32_i_2 + uvec3(x, y, z);
                uint index = x16_uint_array_index(x16_i);
                uint mask = x16_uint_bit_mask(x16_i);
                at_least_one_occluding =
                    at_least_one_occluding || (local_copy_x16[index] & mask) != 0;
            }
        }
    }

    chunk_block_presence(chunk_i).x32[x32_index] = at_least_one_occluding;
}
